[1;31m[error][0m a uenv is already running
[1;31m[error][0m a view is already loaded: {'path': PosixPath('/user-environment'), 'name': 'default'}
[1;31m[error][0m a uenv is already running
[1;31m[error][0m a view is already loaded: {'path': PosixPath('/user-environment'), 'name': 'default'}
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/1B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/1B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 0", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.12484s.

Running...
 Run 1:
  0.00472s: started 0
  27.26792s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.02645s.
Completed after reaching confidence interval, terminated after 1 runs taking 27.29 seconds.
Writing data & meta-data took 0.01645s.
Overall took 27.43631s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/4B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/4B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 2", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04395s.

Running...
 Run 1:
  0.00113s: started 0
  25.19134s: awaited 0
  Data collection took 0.00025s.
  Convergence check took 0.00082s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.19 seconds.
Writing data & meta-data took 0.00886s.
Overall took 25.24529s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/8B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/8B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 3", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.05072s.

Running...
 Run 1:
  0.0011s: started 0
  25.30858s: awaited 0
  Data collection took 0.00025s.
  Convergence check took 0.00082s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.31 seconds.
Writing data & meta-data took 0.01021s.
Overall took 25.37066s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/64B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/64B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 6", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.0515s.

Running...
 Run 1:
  0.0011s: started 0
  25.13048s: awaited 0
  Data collection took 0.00023s.
  Convergence check took 0.00082s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.13 seconds.
Writing data & meta-data took 0.00922s.
Overall took 25.19233s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/512B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/512B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 9", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04473s.

Running...
 Run 1:
  0.00108s: started 0
  25.30649s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.00082s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.31 seconds.
Writing data & meta-data took 0.01034s.
Overall took 25.36269s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/4KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/4KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 12", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03993s.

Running...
 Run 1:
  0.00111s: started 0
  25.75643s: awaited 0
  Data collection took 0.00023s.
  Convergence check took 0.00082s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.76 seconds.
Writing data & meta-data took 0.00955s.
Overall took 25.80704s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/32KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/32KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 15", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04096s.

Running...
 Run 1:
  0.00111s: started 0
  25.45409s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.0008s.
Completed after reaching confidence interval, terminated after 1 runs taking 25.46 seconds.
Writing data & meta-data took 0.00953s.
Overall took 25.50569s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/256KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/256KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 18", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.09502s.

Running...
 Run 1:
  0.00103s: started 0
  25.6454s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.00082s.
 Run 2:
  0.0013s: started 0
  24.82468s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00073s.
 Run 3:
  0.10273s: started 0
  24.6083s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00072s.
 Run 4:
  0.06357s: started 0
  24.32124s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00076s.
Completed after reaching confidence interval, terminated after 4 runs taking 99.4 seconds.
Writing data & meta-data took 0.00997s.
Overall took 99.50859s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/2MiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/2MiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 21", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.05356s.

Running...
 Run 1:
  0.00107s: started 0
  25.61094s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.00081s.
 Run 2:
  0.07807s: started 0
  24.54647s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00077s.
 Run 3:
  0.11059s: started 0
  24.7867s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00073s.
 Run 4:
  0.0429s: started 0
  25.33053s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00073s.
 Run 5:
  0.06098s: started 0
  25.71623s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00071s.
 Run 6:
  0.00127s: started 0
  24.99352s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00071s.
 Run 7:
  0.00124s: started 0
  25.70909s: awaited 0
  Data collection took 0.00012s.
  Convergence check took 0.00071s.
 Run 8:
  0.00124s: started 0
  24.55046s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00074s.
 Run 9:
  0.00132s: started 0
  25.83664s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00071s.
 Run 10:
  0.00125s: started 0
  24.74485s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.0007s.
Completed maximum number of runs, terminated after 10 runs taking 251.84 seconds.
Writing data & meta-data took 0.01065s.
Overall took 251.90132s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/16MiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/16MiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 24", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03487s.

Running...
 Run 1:
  0.0011s: started 0
  25.86452s: awaited 0
  Data collection took 0.00024s.
  Convergence check took 0.00082s.
 Run 2:
  0.09294s: started 0
  25.98548s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00073s.
 Run 3:
  0.00126s: started 0
  25.23641s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00074s.
 Run 4:
  0.00125s: started 0
  25.3748s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00075s.
 Run 5:
  0.12164s: started 0
  26.29213s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00075s.
 Run 6:
  0.00127s: started 0
  25.37048s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00072s.
 Run 7:
  0.00125s: started 0
  25.49653s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00074s.
 Run 8:
  0.00127s: started 0
  25.35962s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00077s.
 Run 9:
  0.00123s: started 0
  25.40726s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00073s.
 Run 10:
  0.00123s: started 0
  25.30911s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00073s.
Completed maximum number of runs, terminated after 10 runs taking 255.71 seconds.
Writing data & meta-data took 0.01046s.
Overall took 255.75594s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/128MiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/128MiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 27", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.08096s.

Running...
 Run 1:
  0.00109s: started 0
  31.00863s: awaited 0
  Data collection took 0.00023s.
  Convergence check took 0.00084s.
 Run 2:
  0.0012s: started 0
  30.51884s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00074s.
 Run 3:
  0.00126s: started 0
  30.61392s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00075s.
 Run 4:
  0.00127s: started 0
  29.63361s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00073s.
 Run 5:
  0.00127s: started 0
  29.34924s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00074s.
 Run 6:
  0.00128s: started 0
  31.12037s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00073s.
 Run 7:
  0.00125s: started 0
  30.45765s: awaited 0
  Data collection took 0.00014s.
  Convergence check took 0.00073s.
 Run 8:
  0.00123s: started 0
  30.13499s: awaited 0
  Data collection took 0.00015s.
  Convergence check took 0.00076s.
 Run 9:
  0.13263s: started 0
  31.10271s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00072s.
 Run 10:
  0.10894s: started 0
  30.32949s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00074s.
Completed maximum number of runs, terminated after 10 runs taking 304.28 seconds.
Writing data & meta-data took 0.01059s.
Overall took 304.37103s.
+ for schedule in ./apps_mix/gpubench/mpp-nccl/1B ./apps_mix/gpubench/mpp-nccl/4B ./apps_mix/gpubench/mpp-nccl/8B ./apps_mix/gpubench/mpp-nccl/64B ./apps_mix/gpubench/mpp-nccl/512B ./apps_mix/gpubench/mpp-nccl/4KiB ./apps_mix/gpubench/mpp-nccl/32KiB ./apps_mix/gpubench/mpp-nccl/256KiB ./apps_mix/gpubench/mpp-nccl/2MiB ./apps_mix/gpubench/mpp-nccl/16MiB ./apps_mix/gpubench/mpp-nccl/128MiB ./apps_mix/gpubench/mpp-nccl/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-nccl/1GiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-nccl/1GiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 30", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.02438s.

Running...
 Run 1:
  0.00109s: started 0
  67.32655s: awaited 0
  Data collection took 0.00023s.
  Convergence check took 0.00081s.
 Run 2:
  0.06229s: started 0
  66.15883s: awaited 0
  Data collection took 0.00013s.
  Convergence check took 0.00072s.
Completed after reaching confidence interval, terminated after 2 runs taking 133.49 seconds.
Writing data & meta-data took 0.00946s.
Overall took 133.52126s.
[1;31m[error][0m a uenv is already running
[1;31m[error][0m a view is already loaded: {'path': PosixPath('/user-environment'), 'name': 'default'}
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/1B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/1B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 0", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03425s.

Running...
 Run 1:
  0.0012s: started 0
  600.42023s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.42 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/4B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/4B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 2", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04219s.

Running...
 Run 1:
  0.00112s: started 0
  600.4925s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.49 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/8B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/8B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 3", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03645s.

Running...
 Run 1:
  0.00116s: started 0
  600.34188s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.34 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/64B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/64B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 6", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03245s.

Running...
 Run 1:
  0.00118s: started 0
  600.40975s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.41 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/512B auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/512B', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 9", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04207s.

Running...
 Run 1:
  0.00118s: started 0
  600.3439s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.34 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/4KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/4KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 12", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.05621s.

Running...
 Run 1:
  0.00515s: started 0
  600.54877s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.55 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/32KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/32KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 15", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.05195s.

Running...
 Run 1:
  0.00112s: started 0
  600.55451s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.55 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/256KiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/256KiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 18", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.03864s.

Running...
 Run 1:
  0.00114s: started 0
  600.81262s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.81 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/2MiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4

Passed arguments:
Namespace(app_mix='./apps_mix/gpubench/mpp-cudaaware/2MiB', node_file='auto', numnodes=2, allocationmode='l', allocationsplit='100', minruns=1, maxruns=10, timeout=600.0, alpha=0.05, beta=0.05, ppn=4, convergeall=False, outformat='csv', runtimeout='+file', seed=1, datapath='./data', extrainfo='same_switch', replace_mix_args=None)

Apps:
0: with arguments:"-l 100 -x 21", collection flag: True, ending condition: run until finished.
Split list: [100.0]
Splits: [2]

Node allocation:
Processes per node (ppn): 4
0 on 2 nodes:
['nid001056' 'nid001058']

Schedule:
0.0s: start 0

Preparing took 0.04002s.

Running...
 Run 1:
  0.00111s: started 0
  600.26757s: timed out 0
  No data collection due to timeout.
Completed after timeout, terminated after 0 runs taking 600.27 seconds.
Traceback (most recent call last):
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 595, in <module>
    main()
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 580, in main
    log_data(out_format, data_directory+'/data', data_container_list)
  File "/bret/scratch/cscs/lfusco/blink/runner.py", line 184, in log_data
    dataframe.columns = columns
    ^^^^^^^^^^^^^^^^^
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 6310, in __setattr__
    return object.__setattr__(self, name, value)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "properties.pyx", line 69, in pandas._libs.properties.AxisProperty.__set__
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/generic.py", line 813, in _set_axis
    self._mgr.set_axis(axis, labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/managers.py", line 238, in set_axis
    self._validate_set_axis(axis, new_labels)
  File "/users/lfusco/.local/lib/python3.11/site-packages/pandas/core/internals/base.py", line 98, in _validate_set_axis
    raise ValueError(
ValueError: Length mismatch: Expected axis has 0 elements, new values have 2 elements
+ for schedule in ./apps_mix/gpubench/mpp-cudaaware/1B ./apps_mix/gpubench/mpp-cudaaware/4B ./apps_mix/gpubench/mpp-cudaaware/8B ./apps_mix/gpubench/mpp-cudaaware/64B ./apps_mix/gpubench/mpp-cudaaware/512B ./apps_mix/gpubench/mpp-cudaaware/4KiB ./apps_mix/gpubench/mpp-cudaaware/32KiB ./apps_mix/gpubench/mpp-cudaaware/256KiB ./apps_mix/gpubench/mpp-cudaaware/2MiB ./apps_mix/gpubench/mpp-cudaaware/16MiB ./apps_mix/gpubench/mpp-cudaaware/128MiB ./apps_mix/gpubench/mpp-cudaaware/1GiB
+ for nam in l
+ for split in 100
+ python3 runner.py ./apps_mix/gpubench/mpp-cudaaware/16MiB auto -am l -as 100 -n 2 -e same_switch -mn 1 -mx 10 -t 600 -a 0.05 -b 0.05 -of csv -ro +file -p 4
slurmstepd: error: *** JOB 45900 ON nid001056 CANCELLED AT 2024-03-22T13:51:54 DUE TO TIME LIMIT ***
